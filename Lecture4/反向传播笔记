课时8-9

计算图：
在计算图中，数值结果通过运算门的正向计算（加减乘除、开方、指数等），向后传播，而梯度通过运算门由后向前，
根据各个运算门的不同类型，分别计算其梯度，并与由运算图尾部传来的梯度值相乘，然后继续向前传播。
一些梯度计算简单的运算门可以被看做一个运算门来计算梯度，整个计算图由许多容易计算梯度的运算门连接。

由于神经网络就是由这样的运算门连接而成（运算门也被叫做层），所以在设计神经网络时，首先要统一各个运算门的API。
例如乘法运算门：
class MultiplyGate(object):
    def forward(x, y):
        z = x * y
        self.x = x
        self.y = y
        return z

    def backward(dz): # dz 代表 dL/dz, 由后面的运算门传过来
        dx = self.y * dz # dx 代表 dL/dx = dL/dz * dz/dx
        dy = self.x * dz
        return [dx, dy]

每一个运算门都要记住他的输入数值，因为在反向传播计算梯度时，可能需要用到。

神经网络相当巨大，不能直接写出所有参数的梯度，所以只能使用图结构来进行计算。记录中间值，对每个结点应用前馈、
反馈API，构成图结构。图结构是对所有层以及层与层之间连接的包装，层与层之间的连接是通过向量传递来完成的，实际
应用中，我们传递的是n维张量，也就是n维数组，这些数组在各层之间传递，每层都独自处理前向和后向传播