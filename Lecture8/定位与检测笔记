课时 17-18

Localization and Detection

分类+定位:
    一张图片中只有一个物体

  1. 将定位当做回归问题
    可以将定位问题视作回归问题. 将一张图片经过处理，得到4个代表选框的实数，通常使用选框左上角的X, Y坐标，和选框的宽度、高度. 
    可以使用欧氏距离计算loss

  分类+定位的简单实现：
    1. 训练（或下载）一个分类模型（AlexNet, VGG, GoogLeNet）
    2. 在这个网络里再接上一些新的全连接层（称为回归网络，Regression head）
    3. 使用L2损失和SGD训练回归网络
    4. 在测试时，使用两个网络，分别得到分类和候选框

  回归有两种主要方式:
    不定类回归和特定类回归. 
    不定类回归只产生一个框，特定类回归为所有类别分别产生一个框. 

  回归网络放置的位置：
    1. 放在卷积层之后（Overfeat, VGG）
    2. 放在全连接层之后（DeepPose, R-CNN）


  2. 滑动窗口
    对一张超过网络输入尺寸的图片，分别裁剪图像的不同区域（如4个角落和一个中心）输入到网络中，再将得到的结果进行聚合. 
    对于定位的选框坐标，会根据裁剪的图像位置发生改变. 

  Overfeat: 高效滑动窗口
    将最后的全连接层，通过1x1卷积，变成全卷积网络. 
    这样对于大尺寸图片，不用多次裁剪后重复输入进网络，而是可以将整张图片输入，得到一个代表结果的矩阵. 


目标检测:
    找到一张图片中几个类的所有实例. 

  - 将目标检测当做分类问题

  1. R-CNN
     - 分别使用不同尺寸的窗口，在图片上滑动检测不同位置. 但开销太大.
     - 解决方法是只查看一些有可能出现目标的区域，并对这些区域使用分类器. 这种思想就是Region Proposal.

		Region Proposal（区域推荐）
			在图像中找寻一些整体相似的结构. 当多次使用这个方法，会发现在许多小框区域产生框，其中Selective Search是最有名的候选框生成方法.

      - Selective Search:
        从像素出发，将具有相似颜色和纹理的相邻像素进行合并.
        形成一些相连接的块状区域，然后不断合并，可以得到更大的块状区域，接着把不同规模的各个区域转换成框.
        通过在不同尺度块状区域进行操作，最后在图像中得到许多包含块状物体的框.
        Selective Search 计算速度很快，并且可以减少许多搜索区域.
      Region Proposal 还有许多其他选择，EdgeBoxes方法速度更快

    R-CNN 训练:
      1. 训练（或下载）一个效果很好的分类模型（AlexNet）
      2. 对模型进行微调以用于目标检测，在网络最后加上新的几层来处理新的类别和图像数据中不同的统计特性
        - 更换最后一层的1000个类别标签，变成20个类+1个背景的组合
        - 只需更改最后一层的系数矩阵，初始化并训练.
        - 使用目标检测图片中的+/-区域训练模型
      3. 提取特征
        - 对每一张图片使用Selective Search算法提取出 Region Proposals
        - 对每个区域，将其转换成CNN可输入的固定尺寸，并通过CNN向前传播，保存第5个池化层后得到的特征到硬盘
        - 需要一个很大的硬盘用于存储特征
      4. 为每个类别分别训练一个二分类SVM，用于将这个类别的+标签和-标签区分开（-标签代表除此类以外的其他类）
      5. 边界框回归:
        有时得到的 Region Proposals 不太完美，所以希望为每个类训练一个线性回归模型，通过已缓存的特征，得到对Proposals的更正.
        线性回归对象为由(dx, dy, dw, dh)组成的向量.

    R-CNN缺点:
      1. 测试时很慢: 可能有2000个区域，要对每个区域都运行一遍R-CNN.
      2. SVM和回归部分是离线训练的: CNN的特征没法根据它们的反应进行更新.
      3. 复杂的训练流程比较混乱.


  2. Fast R-CNN
    1. 将高分辨率图像直接输入，并卷积得到第5层的特征图.
    2. 在特征图中使用RoI(Region of Interest) Pooling提取原图中每个Region Proposal对应的特征.
    3. 将提取出特征输入到全连接层，然后连接到一个分类网络和一个回归网络.

	  Region of Interest Pooling:
	    对于高分辨率图像中通过Selective Search等算法得到的候选框，将其投影到卷积特征图中.
	    对裁剪后的特征图进行分区，对每个分区使用最大池化，得到一个固定大小的新特征图.

	  Fast R-CNN 优点
	    1. 通过共享不同目标框的卷积特征的计算，解决了测试速度慢的问题.
	    2. 同时训练所有部分.

	  Fast R-CNN 缺点
	    瓶颈在于推荐区域(Region Proposal)的选取算法Selective Search，不能并行计算，消耗大量时间.


  3. Faster R-CNN
    - 在最后一个conv层后加入一个去区域推荐网络(Region Proposal Network, RPN)来替代额外的区域推荐算法，
      获取卷积层最末端的特征图，从中获得推荐区域.
    - 在RPN之后，使用RoI池化，其它与Fast R-CNN一样.

	  Region Proposal Network(RPN, 区域推荐网络)
	    - 把卷积神经网络的最后一层特征图当做输入，然后将区域推荐网络添加到卷积神经网络之上.
	    - 对特征图进行滑窗(即卷积)操作, 使用256通道的3x3卷积核(或其它大小)对特征图进行卷积，每个卷积区域得到一个256维向量(新特征图大小不变).
	    - 构建两种相似的顶层结构(即输出层)，一个判用于断对应区域中是否包含检测目标，另一个对边界框位置进行回归.
	      上层的256维向量输入，通过分类网络(1通道1x1卷积核)得到一个score，通过回归网络(4通道1x1卷积核)得到一个4维的condition坐标.
	    - 在RPN中，每个滑窗的位置提供了定位信息在原图中的位置(即查看的是图片的哪一个部分)，边界框回归则提供了与当前滑窗有关的更好的位置信息.

	    - 在实际操作中，并不直接对特征图中的位置进行回归，而是使用几个形状固定的框(anchor box)，可以想象这些不同形状和尺寸的框，
	      根据特征图点到原始图片点的关联，覆盖到原始图片上.
	    - 使用n个卷积框(anchor box)对特征图进行卷积. 每个框对每一个区域分别进行卷积，每次产生一个评分来判断框内是否有检测目标，
	      它还会输出4个回归坐标点，得到正确的框的位置.

	  Faster R-CNN 训练
	    将RPN整合到一个大网络中(即网络中有一个内置的区域推荐网络)，并产生4个损失值(loss).
	    1. RPN classification (anchor good/bad)，表示推荐区域内是否包含一个检测目标.
	    2. RPN regression (anchor -> proposal)，得到推荐区域框的坐标.
	    根据RPN中得到的推荐区域位置，在特征图中进行RoI池化，然后做Fast R-CNN中相同的工作.
	    3. Fast R-CNN classification (over classes)，表示目标所属类别
	    4. Fast R-CNN regression (proposal -> box)，获得正确的推荐区域


	- 将目标检测当做回归问题

	YOLO
		- 将输入的图像划分成许多空间网格(通常是7x7的网格，网格大小随图像尺寸变化)
		- 对于每个网格中的元素，预测 B个边界框(B通常为2)的4个坐标+1个置信度 和 对于每个类别的评分

		检测问题变成回归问题，即输入一张图片，会输出一个 7x7x(5xB + C)的张量. 对于回归问题，可以使用CNN训练.

		YOLO 的问题
			- 它的模型输出是有上限的，如果测试数据和训练数据中有许多ground truth，就可能出现一些问题.

		YOLO 优点
			- 速度非常快，比Faster R-CNN还快，如果GPU不是很好，也可以使用YOLO获得不错的效果

		YOLO 缺点
			- 检测效果并不是很好